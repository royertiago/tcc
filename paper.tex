\documentclass[12pt]{article}
\usepackage{sbc/template}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{example}[definition]{Example}
\newtheorem{proposition}[definition]{Proposition}

\usepackage{complexity}

\sloppy

\title{Blum axioms and nondeterministic computation of functions}

\author{Tiago Royer\inst{1}, Jerusa Marchi\inst{1}}

\address{
    Universidade Federal de Santa Catarina --- Departamento de Informática e Estatística \\
    \email{royertiago@gmail.com, jerusa.marchi@ufsc.br}
}

\begin{document}

\maketitle

\begin{abstract}
    In his doctoral thesis,
    Manuel Blum proposed two axioms for complexity measures
    that allows us to talk about complexity in an axiomatic manner.
    His axioms does not even specify the machine model
    --- it just requires it to satisfy some properties.
    Blum axioms, however,
    are defined in the context of function computation.
    This restriction is easy to implement with deterministic machines,
    since there is only one output for a given input,
    but how can a nondeterministic Turing machine compute a function?
    This paper surveys techniques to associate
    nondeterministic machines with functions
    and analyze how they interact with computational complexity.
\end{abstract}

\section{Introduction}

In Theory of Computation,
we usually use languages
to mathematically model problems in the real world.
Decision problems (``yes/no'') are mapped to languages in a very natural way,
by just putting every ``yes'' instance in the language,
and leaving the rest out.
Search problems usually are rewritten as a decision problem,
and then this problem is converted to a language.
For instance,
the task of finding a satisfying assignment for a Boolean formula
is reinterpreted to the task of deciding whether this assignment exists,
and this task is then converted to a language
--- in this example we have $\SAT$, the Boolean satisfiability problem.
This does the trick when it comes to proving that something is hard;
for instance, if we show that the decision problem is $\NP$-hard or undecidable,
then intuitively the corresponding search problem must be at least as hard.
Therefore,
concepts like ``decidable'', ``$\NP$-complete'', ``polynomial-time decidable''
arise naturally in the context of decision problems.

However, even from the theoretical standpoint,
it is useful to extend these concepts to functions.
For instance,
the concept of polynomial-time computable functions
are required to define Karp reductions \cite[p.~42]{AroraBarak2009}.
For single-tape deterministic Turing machines,
this definition is easy to extend:
A function $f : \{0, 1\}^* \to \{0, 1\}^*$
is said to be \emph{polynomial-time computable}
if there is a Turing machine $M$ and a polynomial $p$ such that,
when given the string $x$ as input,
$M$ halts with $f(x)$ in its tape within $p(|x|)$ steps.

Most extensions to this basic model,
like the use of several tracks, or several tapes, or multidimensional tapes,
can be easily incorporated in the definition of polynomial-time computable.
Except nondeterminism.
We hit a wall right in the start:
how does a nondeterministic machine computes a function in the first place?

This paper presents several attempts to establish
how a nondeterministic Turing machine could compute a function,
and to extend the concept of ``polynomial-time computable'' under each definition.
Section~\ref{sec:quality-standards} sets reasonableness criteria
to both the definition of function computation and complexity of the computation.
Section~\ref{sec:nondeterministic_computation_of_functions}
presents and criticizes the several definitions.

\section{Quality Standards}
\label{sec:quality-standards}

Since we are trying to make a definition of non-deterministic computation of functions,
this definition must encompass both
the ``computation'' part and the ``non-deterministic'' part.

In the context of deciders,
allowing doubly-infinite tapes and multiple tapes,
although simplifies the design and increases the efficiency of the machine,
does not expand the class of languages that can be decided or recognized by the machine.
That is, both models are \emph{computationally equivalent}.
Therefore,
our definition must produce an equivalent model
--- every function that can be computed by deterministic means
must be computable under our new definition and vice-versa.
This is the ``computation'' part.

But nondeterministic deciders,
although computationally equivalent to deterministic ones,
are apparently exponentially faster.
That is, while we have linear-time non-deterministic algorithms for Boolean satisfiability,
the best known deterministic algorithms are still exponential in the worst case.
Nondeterminism seems special in this sense;
although other extensions (multiple tapes and doubly-infinite tapes)
can be simulated under just a polynomial slowdown,
the simulation of nondeterminism seems to require exponential slowdown.%
\footnote{
    Simulating nondeterminism under a polynomial slowdown would show that $\P = \NP$;
    showing that the slowdown must be exponential would show that $\P \neq \NP$.
    Although most researchers expect the later to be the case~\cite[p.~54]{Gasarch2012},
    as Papadimitriou noted~\cite[p.~412]{Papadimitriou1994},
    in the absence of a proof that $\P \neq \NP$
    we should not be too emphatic in stating the simulation \emph{require}
    (as opposed to \emph{seemingly require}) exponential slowdown.
}
Therefore,
our definition must exhibit this apparent exponential speedup
when computing, for instance, the characteristic function\footnotemark{} of $\SAT$.
\footnotetext{
    The characteristic function of a set $A \subseteq \Sigma^*$
    is the function $f$ defined by
    \begin{equation*}
        f(x) = \begin{cases}
            1, & \text{if $x \in A$}. \\
            0, & \text{if $x \notin A$}.
        \end{cases}
    \end{equation*}
}
This is the ``non-deterministic'' part.

Section~\ref{sec:godel-numberings}
presents a formalization of the ``computation'' part
and section~\ref{sec:blum-axioms}
presents a formalization of the ``non-deterministic'' part.

\subsection{Reasonableness criterion: acceptable Gödel numberings}
\label{sec:godel-numberings}

One of the most important theoretical results concerning Turing machines
is the existence of undecidable problems.
Namely, the \emph{halting problem}
(the task of deciding whether a given Turing machine will halt on a given input)
cannot be solved by Turing machines \cite[p.~23]{AroraBarak2009}.
The formalization (and proof) of this fact
requires the definition of some sort of \emph{encoding};
since Turing machines can only reason about strings,
we need somehow to encode Turing machines into strings,
to be able to pose the halting problem as a language question.

Each Turing machine can be associated
to the corresponding partial recursive function it computes.
There are several ways to encode Turing machines as strings,
but what is most important about them is that they allow us
to manipulate these partial recursive functions \emph{indirectly}
--- partial recursive functions are (potentially) infinite objects,
so we cannot write them down on a Turing machine tape,
but we \emph{can} write the encoding of a Turing machine that compute these functions.

Therefore,
these encodings provide a way to associate a string
(which is a finite, manipulable object)
with a partial recursive function
(which is an infinite, mathematical, ``untouchable'' object).
Encodings are \emph{enumerations} of all partial recursive function.

In some sense,
we are going the opposite direction:
instead of associating functions with strings,
we want to associate machines with functions.

One important feature about the standard encodings of deterministic Turing machines
is the Universal Turing Machine Theorem:
the existence of a partial recursive function
$U: \{0, 1\}^* \times \{0, 1\}^* \to \{0, 1\}^*$
% Não sei se $U$ é um bom nome...
such that, if $w$ encodes the machine $M$,
then $U(m, x)$ is the result of running the machine $M$ on $x$.
The machines that compute $U$ are called \emph{universal Turing machines}.

The concept of \emph{acceptable Gödel numbering}
(\cite[p.~41]{Rogers1987},~\cite[p.~324]{Blum1967})
encompasses the existence of universal machines and a little more.
We will use it as our reasonableness criteria to our definitions.%

\begin{definition}
    Let $\mathcal P$ be the set of all partial recursive functions.
    An \emph{acceptable Gödel numbering}
    is a function $\phi : \{0, 1\}^* \to \mathcal P$,
    that associates each string (or program)\footnotemark $w \in \{0, 1\}^*$
    \footnotetext{
        In texts like Rogers'~\cite{Rogers1987},
        the partial recursive functions have the naturals as domain and codomain
        (that is, they are of the form $f: \mathbb N \to \mathbb N$),
        and Gödel numberings associates natural numbers with recursive functions.
        In this paper we will work with binary strings instead of numbers,
        which will simplify the definition of complexity classes
        and allows us to think the string $w$ as a \emph{program} for $\phi_w$
        (see example~\ref{c}).
    }
    to a function $\phi_w \in \mathcal P$,
    that satisfies
    \begin{enumerate}
        \item $\phi$ is surjective;
            that is, every partial recursive function $f \in \mathcal P$
            has a program $w \in \{0, 1\}^*$ such that $\phi_w = f$;
            \label{surjectiveness}
        \item There is a partial recursive function
            $U:\{0, 1\}^* \times \{0, 1\}^* \to \{0, 1\}^*$ such that,
            for every $w$ and $x$,
            $U(w, x)$ is defined if and only if $\phi_w(x)$ is defined,
            and, in this case,
            \begin{equation*}
                U(w, x) = \phi_w(x);
            \end{equation*}
            \label{universal-tm}
        \item There is a total recursive function
            $\sigma:\{0, 1\}^* \times \{0, 1\}^* \to \{0, 1\}^*$ such that,
            for every $y$,
            $\phi_w(x, y)$ is defined if and only if $\phi_{\sigma(w, x)}(y)$ is defined,
            and, in this case,
            \begin{equation*}
                \phi_w(x, y) = \phi_{\sigma(w, x)}(y).
            \end{equation*}
            \label{smn-theorem}
    \end{enumerate}
\end{definition}

This concept captures the intuitive notion of
``well-behaved numbering''.

Condition~\ref{surjectiveness}
guarantees that the image of~$\phi$ is all of~$\mathcal P$,
so that the numbering neither ``forgets'' a partial recursive function
nor generate a function that is not partial recursive.

Condition~\ref{universal-tm} is the universal Turing machine theorem.

Condition~\ref{smn-theorem} is the ``little more'' we mentioned earlier.
It is known as the $S_{mn}$ theorem \cite[p.~24]{Rogers1987}.
Essentially,
given a partial recursive function of two variables,
we can obtain a partial recursive function of one variable
by fixing the first argument.
The function $\sigma$ provides a systematic way of doing this:
given a description $w$ of a partial recursive function of two variables
and the value $x$ to be fixed as the first variable,
the function returns a machine $\sigma(w, x)$
that computes the same function as $w$ but with the first argument fixed as $x$.

\begin{example}\label{standard-numbering}
    Any encoding of deterministic Turing machines as a binary string
    yields an acceptable numbering of the recursive functions.
\end{example}

\begin{example}\label{c}
    Any programming language can be understood as an acceptable Gödel numbering.
    For example,
    if we restrict a \texttt C program
    to perform input and output only using the standard input and standard output
    (that is, forbid interactions with the user, file reading, GUIs,
    access to system clock, etc.),
    the resulting program will map a binary input to a binary output,
    characterizing a partial recursive function.
    Thus, we can see a \texttt C compiler
    as an implementation of an acceptable Gödel numbering.\footnote{
        Note we are ignoring here issues like compilation and run-time errors.
        These can be dealt with as in the case of Turing machines:
        any invalid program will signify some fixed partial recursive function
        (say, the function that is defined nowhere);
        and any invalid step in computation
        makes the function to be not defined on that input.
    }
\end{example}

\begin{example}
    We can also think of less orthodox numberings.

    As two-stack deterministic pushdown automata are equivalent to Turing machines%
    ~\cite[p.~172]{HopcroftUllman1979},
    any encoding of these kind of automaton yields acceptable Gödel numberings.

    Unrestricted grammars can also simulate Turing machines%
    ~\cite[p.~221]{HopcroftUllman1979};
    so if a grammar $G$ generate pairs $(x, y)$,
    define the corresponding partial recursive function $f$
    by $f(x) = y$ if,
    among all the pairs whose first element is $x$,
    the pair $(x, y)$ is the one with smallest number of productions
    (leave $f$ undefined if there are ties or no pairs with $x$ as first element).
    (Choosing the pair $(x, y)$ with the smaller number of productions
    allows a Turing machine to simulate this function
    by doing a breadth-first search in the grammar,
    guaranteeing the function is partial recursive.)

    And, as an off-line Turing machine
    (a machine with a special read-only tape for its input)
    can simulate any Turing machine without ever writing a $0$ over a~$1$
    \cite[p.~174]{HopcroftUllman1979},
    we can associate an encoding of a off-line Turing machine
    with the function that counts the number of times
    it writes a $0$ over an $1$ before halting
    (the number can be converted to binary and have its most significant digit removed
    to generate all possible binary strings).
    (The machine can choose how many times it will write a $0$ over an $1$,
    thus we can generate any partial recursive function by manipulating this choice.)
\end{example}

There are several interesting properties we can show about acceptable Gödel numberings.
For instance,
if $\phi$ and $\phi'$ are any two such numberings,
there is a total recursive function that converts programs for $\phi$
into programs for $\phi'$;
that is, there is a total recursive function $f : \{0, 1\}^* \to \{0, 1\}^*$
such that, for every program $w$,
\begin{equation*}
    \phi_w = \phi'_{f(w)}.
\end{equation*}
To show this,
we can use the $\sigma$ function for $\phi'$
to fix the input program as the first variable of the $U$ function for $\phi$.
With a bit more work,
it is possible to make $f$ bijective \cite[p.~25]{Soare1987}.

Another important theorem is the recursion theorem
\cite[p.~181]{Rogers1987}.
It states that, if $\phi$ is any acceptable Gödel numbering
and $f$ is any total recursive function,
then there is some program $w_0$ such that $\phi_{w_0} = \phi_{f(w_0)}$.
That is,
if $f$ is any systematic transformation on programs,
there is a program $w$ (a fixed point for $f$) whose meaning under $\phi$ is unchanged.
The recursion theorem can be used,
for example, to show the existence of quines
(programs whose output are their own source codes)
in any Turing-complete programming language:
choose $f$ to be the function that, given a program $w$,
returns another program $f(w)$ that prints the string $w$ when run.
(For Turing machines, for instance,
we can encode the bits of $w$ in the transition table of $w$.)
Then, by the recursion theorem,
there is some program $w_0$ that is equivalent to its transformed version $f(w_0)$;
thus, $w_0$ already writes the string $w_0$, its own source code.
Therefore, any programming language has quines \cite[p.~227]{Kozen2006}.

\subsection{Efficiency criterion: Blum axioms}
\label{sec:blum-axioms}

The \emph{complexity} of a computation is how much of a resource
that is invested in that computation~\cite[p.~285]{HopcroftUllman1979}.
For each model of computation and each resource under that model,
we can establish a \emph{complexity measure} concerning that resource.
This section is devoted to formalizing this notion.

Note that the complexity measure must be subordinated to the machine model.
For instance,
if we are talking about pushdown automata with two stacks,
we could restrict the machine to operate on one stack each time
(that is, each move must alter at most one stack)
and measure the number of times the automaton switches its ``active'' stack.
This complexity measure makes no sense for Turing machines,
which have no stacks.

Therefore,
we must have an acceptable Gödel numbering $\phi$
to discuss complexity.
We can think that a complexity measure is a way of associating
each program $w$ and each input $x$
with a number $n$,
which is the amount of the measured resource it takes to obtain $\phi_w(x)$
using the program $w$.

As we did with the machine encodings,
we will impose some restrictions on what can be a complexity measure
to be able to manipulate it (at least indirectly).
In our case,
we will use Blum axioms~\cite[p.~324]{Blum1967}.

\begin{definition}
    Given an acceptable Gödel numbering $\phi$,
    a \emph{complexity measure} for $\phi$
    is a function $\Phi:\Sigma^* \times \Sigma^* \to \mathbb N$ of two variables
    that satisfies: \cite[p.~324]{Blum1967}
    \begin{enumerate}
        \item For every $w$ and $x$,
            $\phi_w(x)$ exists if and only if $\Phi(w, x)$ exists.
        \item For every string $w$, $x$ and every natural number $k$,
            the predicate ``$\Phi(w, x) = k$?'' is decidable.
    \end{enumerate}
\end{definition}

$\Phi(w, x)$ is the complexity of computing $\phi_w(x)$
using the program $w$.
The first axiom says that it only makes sense
to talk about the complexity of a computation that ends.
The second axiom gives minimum tools to manipulate $\Phi$ indirectly,
in the same manner we require $\phi$ to be an \emph{acceptable} Gödel numbering.

\begin{example}
    The standard measures of time and space can be constructed
    over the acceptable numbering of example~\ref{standard-numbering}.
    The time complexity is simply the number of moves the machine makes before halting;
    if it does not halt, leave it undefined.
    As this number is only defined if the machine halts,
    the first axiom is satisfied;
    and, to decide the predicate of the second axiom,
    we can simply run the machine for $k$ moves and see whether it halted.

    Space complexity requires extra care,
    because the machine might not halt
    even though the number of tape cells it uses is limited.
    So, define the corresponding function $\Phi$ by
    \begin{equation*}
        \Phi(w, x) = \begin{cases}
            k, &\text{if $w$ scans exactly $k$ tape cells and halts when processing $x$}\\
            \text{undefined}, &\text{if $w$ never halts on $x$}
        \end{cases}
    \end{equation*}
    This function satisfies the first axiom,
    and, as there is a finite number of states of computation
    in which at most $k$ tape cells are scanned,
    the predicate of the second axiom can be verified
    by keeping all intermediate steps of computation
    and checking to see whether any state repeat
    (in this case, the machine loops and the complexity is undefined).
\end{example}

\begin{example}
    As with acceptable Gödel numberings,
    we can also measure less usual resources.
    For example, we can satisfy the Blum axioms by
    counting the number of times a machine changes a symbol in the tape,
    the number of times the tape head moves right,
    or the number of times a two-stack pushdown automata
    pops a symbol from the second stack.
\end{example}

\begin{definition}
    Given a complexity measure $\Phi$ for an acceptable Gödel numbering $\phi$
    and a total recursive function $f : \mathbb N \to \mathbb N$,
    define the \emph{complexity class} $\mathcal C_\Phi(f)$ by
    (\cite[p.~232]{Kozen2006})
    \begin{equation*}
        \mathcal C_\Phi(f) = \{
            \phi_i \mid \Phi_i(x) \leq f(|x|)\ \text{almost everywhere\footnotemark}
        \}.
    \end{equation*}
    \footnotetext{
        \emph{Almost everywhere} means that the inequality $\Phi_i(x) \leq f(|x|)$
        holds for all but a finite number of different $x$.
    }
\end{definition}

This formalizes the notion of complexity class.
There are some important theorems concerning complexity classes
under the Blum axioms;
we mention only the Union Theorem \cite[p.~234]{Kozen2006}.
It states that,
if $\{f_i\}$ is any recursive list of increasing functions
such that $f_i(n) \leq f_{i+1}(n)$ for all $x$
(that is, each $f_i$ is greater than the previous),
then there is some function $g$ such that
\begin{equation*}
    \mathcal C_\Phi(g) = \bigcup_{i \in \mathbb N} \mathcal C_\Phi(f_i).
\end{equation*}
That is, the class $\mathcal C_\Phi(g)$ contains \emph{exactly}
all functions present in the classes $\mathcal C_\Phi(f_i)$.
Choosing $\Phi$ as the time complexity and $f_i(n) = n^i$
(the polynomial functions),
the union in the right is exactly the class $\P$,
the problems solvable in polynomial time.
By the Union Theorem, $\P$ is $\mathcal C_\Phi(g)$
for some recursive function $g$,
so, even though $\P$ does not have an easily specifiable bounding function,
such function exists nevertheless.

\section{Nondeterministic computation of functions}
\label{sec:nondeterministic_computation_of_functions}

This section surveys four approaches
for defining nondeterministic computation of functions.

Sections \ref{sec:godel-numberings} and~\ref{sec:blum-axioms}
introduced the concept of acceptable Gödel numbering,
the Blum axioms,
and its complexity classes.
As we want to regard these concepts as ``quality requirements''
for the definitions,
we will analyze each of them to see whether they define acceptable Gödel numberings,
the analogous time complexity defines a Blum complexity measure,
and that the characteristic function of the Boolean satisfiability problem
can be solved in ``polynomial time'' according to that complexity measure.

\subsection{Hopcroft-Ullman's definition}

\begin{definition}[Hopcroft and Ullman's definition\footnotemark]
    \footnotetext{
        Hopcroft and Ullman's original definition \cite[p.~313]{HopcroftUllman1979}
        was defined in the context of computation of integer functions.
        We are rephrasing here in terms of strings,
        but keeping the relation they imposed on the execution branches.
    }
    If $w$ is an encoding for the Turing machine $M$,
    we say that $\phi_w(x) = y$ if and only if,
    when processing $x$,
    there is some branch of $M$ that halts with $y$ in the tape,
    and there is no branch that halts with some $z \neq x$ in the tape.
\end{definition}

The problem with their definition is that $\phi_w(x)$ is allowed to be defined,
even if some branch of computation does not halt.
This allows us to solve the complement of the halting problem.

\begin{proposition}
    The function partial $f: \Sigma^* \times \Sigma^* \to \{0, 1\}$ defined by
    \begin{equation*}
        f(w, x) = \begin{cases}
            1, & \text{if the machine $w$ does not halt on $x$.} \\
            \text{undefined}, &\text{if $w$ never halts on $x$.}
        \end{cases}
    \end{equation*}
    is not computable,
    but can be computed by a nondeterministic Turing machine under
    Hopcroft and Ullman's definition.
\end{proposition}

\begin{proof}
    Note that the domain in which $f$ is defined is exactly
    the complement (under $\Sigma^*$) of the halting problem.
    If $f$ were computable,
    there would be a deterministic machine that could compute it;
    we could, then, modify the machine to accept all inputs in the domain of $f$
    (all inputs that have some output through $f$),
    thus recognizing (albeit not deciding) the complement of the halting problem.
    But, as the halting problem itself is computable but not decidable,
    its complement cannot also be --- otherwise both would be decidable,
    a contradiction.

    But $f$ can be computed under Hopcroft and Ullman's definition as follows:
    on input $(w, x)$,
    create two branches of computation.
    On the first, write $1$ on the tape and halt.
    On the second, simulate the universal Turing machine $U$ in the input,
    and if $U$ halts, write $0$ on the tape and halt too.

    If $w$ halts on $x$,
    there will be two halting branches of computation,
    each writing a different value in the tape,
    so, by definition, the function is not defined on this input.
    If $w$ never halts,
    then only the first branch will halt
    (and with $1$ written on the tape),
    so the function is defined on this input and its value is $1$.

    Thus, under Hopcroft and Ullman's definition,
    this machine computes the function $f$,
    which we already shown to be noncomputable.
\end{proof}

Therefore,
using Hopcroft and Ullman's definition,
we could enumerate functions that are not computable;
so, the image of the corresponding ``Gödel numbering''
would include noncomputable functions.

We can try to fix this definition by forcing all branches to halt;
but then, as all branches are required to return the same value,
the machine will be (almost) deterministic.
Therefore, if there is a machine $M$ that computes the characteristic function
of the satisfiability problem in nondeterministic polynomial time,
we could simulate $M$ on a given input,
choosing (say) always the first option when confronted with nondeterminism.
If this branch of computation returns $1$,
then every branch returns $1$ and the input is satisfiable;
if this branch returns $0$, every branch returns $0$ and the input is unsatisfiable.
We thus could solve $\SAT$ in \emph{deterministic} polynomial time.

Therefore, with this restriction,
we lose the apparent exponential speed up in computation time
we have when using nondeterminism.
We thus will analyze the following models
to see whether they also suffer from this problem.

\subsection{Goldreich's definition}

\begin{definition}[Goldreich's definition]
    Let $\bot$ be some special symbol not in $\{0, 1\}^*$.
    (This symbol will represents ``don't know'')
    A nondeterministic machine $M$ computes the function $f$ if,
    when processing the input $x$,
    both the following conditions hold \cite[p.~168]{Goldreich2008}:
    \begin{itemize}
        \item Every branch of $M$ halts
            and outputs either $f(x)$ or $\bot$.
        \item At least one branch of $M$ halts with $f(x)$ on the tape.
    \end{itemize}
\end{definition}

The extra symbol $\bot$ sidesteps the problems of a branch looping forever.
Now,
every branch is required to halt for the value to be defined.
Thus,
we can convert a nondeterministic Turing machine to a deterministic machine
that compute the same function,
albeit with an exponential slowdown
--- the deterministic machine just need to simulate all branches until completion,
to actually be sure every branch halts;
if some branch do not halt,
then the simulating machine will not halt either,
but the function is not defined in this case,
so this behavior is correct.

Also, a deterministic machine functions exactly the same way under Goldreich's definition,
so we can convert mechanically
between the numbering corresponding to this definition
and a standard numbering for deterministic machines.
Therefore,
to show the universal machine theorem and the $S_{mn}$ theorem,
we can first convert the machine in question to a deterministic machine
and use their theorems.
Thus, this definition comply with the requirements to being an acceptable Gödel numbering,

To establish a complexity measure,
we can count the number of steps of a branch with most steps,
and leave it undefined if some branch loops forever.
--- this is the same method
we use to evaluate the time complexity of a nondeterministic decider.
Leaving undefined if a branch loops forever guarantees the first Blum axiom is satisfied.
And, to decide the predicate of the second axiom,
we can simply run all the branches of the machine for the specified number of steps.
Every branch has to halt within that number of steps,
and some branch must take exactly that number,
for the predicate to be true.

So, Goldreich's definition defines an acceptable Gödel numbering
and we can form a complexity measure that satisfies Blum axioms.
But, again,
we have trouble with the ``exponential speedup'' requirement.

At least partially,
we can compute the characteristic function of the satisfiability problem
in linear time using this model.
The machine $M$ that will do the calculation will guess an assignment
and write $1$ if it is satisfying and write $\bot$ if it isn't.
This computes in linear time the function $f$, defined by
\begin{equation*}
    f(\varphi) = \begin{cases}
        1, & \text{if $\varphi$ is satisfiable.} \\
        \text{undefined}, & \text{if $\varphi$ is unsatisfiable.} \\
    \end{cases}
\end{equation*}
However,
this function falls short of being exactly $\SAT$'s characteristic function:
$f(\varphi)$ ought to be zero for unsatisfiable formulas $\varphi$.
Although we cannot prove a strong assertion as
``if this works then $\P = \NP$'',
we can come close.

\begin{proposition}
    If there is a nondeterministic Turing machine
    that computes in polynomial time, according to Goldreich's definition,
    the characteristic function of the satisfiability problem,
    then $\NP = \coNP$.
\end{proposition}

($\NP = \coNP$ implies that $\NP = \PH$; that is,
the polynomial hierarchy collapses to the first level \cite[p.~280]{Kozen2006}.)

\begin{proof}
    Suppose $M$ is the machine that computes $\SAT$'s characteristic function,
    under Goldreich definition, in polynomial time.

    The characteristic function of $\SAT$ is a total function,
    and its only outputs are $0$ and $1$.
    Therefore, in every computation of $M$,
    there is at least one branch that writes something different that $\bot$ on the tape,
    and whatever it writes is the correct answer.
    So, if we convert this to a nondeterministic decider and invert the output
    (branches that write $0$ will accept the input and vice-versa;
    branches that write $\bot$ always reject),
    any satisfiable formula will be rejected,
    because no branch of $M$ ever writes $0$ on the tape for these formulas,
    and any unsatisfiable formula will be accepted,
    because at least one branch of $M$ writes $0$ for these formulas.
    we can decide $\overline \SAT$, the complement of $\SAT$.

    Since $\overline \SAT$ is $\coNP$-complete,
    the existence of such a machine $M$
    would show that $\coNP \subseteq \NP$,
    and this implies that $\coNP = \NP$.\footnote{
        To see why $\coNP \subseteq \NP$ implies $\coNP = \NP$,
        pick a language $L \in \NP$.
        Its complement $\overline L$ is in $\coNP$, by the definition of $\coNP$.
        But by hypothesis, $\overline L$ is in $\NP$,
        so, by the definition of $\coNP$,
        its complement, $\overline{\overline L} = L$ is in $\coNP$,
        thus showing $\coNP = \NP$.
    }
\end{proof}

Therefore, even though Goldreich's definition
yields an acceptable Gödel numbering and a Blum complexity measure,
it also have trouble in transposing the exponential speedup
we have using nondeterminism.

\subsection{Proposed definition}

Analyzing the problems with the first two definitions,
we know the nondeterministic machine must be allowed to return several values
(one for each branch)
and somehow pick only one to be the value of the function.

If $M$ is any deterministic decider for the language $L$,
we can create a machine that computes the characteristic function of $L$
by running $M$ and returning $1$ if $M$ accepted and $0$ if it rejected.

If we apply this transformation to a nondeterministic machine
that recognizes the Boolean satisfiability problem,
then, when running this machine,
we have three possible results.
\begin{itemize}
    \item For tautological formulas,
        the set of possible answers is only $\{1\}$.
    \item For contradictory formulas,
        the set of answers is $\{0\}$.
    \item For satisfiable formulas that are not tautological,
        we have both values: $\{0, 1\}$.
\end{itemize}
We want the return value for all satisfiable formulas to be $1$
and for unsatisfiable formulas to be $0$.
Note that this corresponds exactly to the maximum value of each set;
so,
our definition of nondeterministic computation of functions
will preserve exactly this behavior.

\begin{definition}[Proposed definition]
    Let $M$ be a nondeterministic Turing machine,
    and $x$ an input.
    If every branch of $M$ halts when processing $x$,
    the value of the function computed by $M$ on $x$
    is the lexicographically maximum
    between all strings written in the computation branches.
    If some branch does not halt, leave the function undefined in $x$.
\end{definition}

The same reasoning of Goldreich's definition applies here;
therefore, we have an acceptable Gödel numbering,
and counting steps of the deepest branch
(as in Goldreich's definition)
yields a Blum complexity measure.

And, using exactly the algorithm mentioned above,
we can compute the characteristic function of the satisfiability problem
under linear time;
thus, this definition meets all the requirements
proposed in the beginning of section~\ref{sec:nondeterministic_computation_of_functions}.

\subsection{Krentel's $\OptP$ class}

From the last two definitions,
we know we must somehow allow the machine to return several values
and pick only one to be the return value.

We can arrive at the definition proposed by Krentel
analyzing the behavior of a nondeterministic machine to solve the satisfiability problem
that has undergone the process applied to deterministic machines
to transform a decider in a computer for the characteristic function.
More precisely,
pick $M$ a nondeterministic decider for $\SAT$,
and make $M$ write $1$ in the tape if it found a satisfying assignment
and $0$ if it didn't.
The propositional formulas will fall in three categories.
\begin{itemize}
    \item Tautological formulas.
        The set of possible answers for these formulas is only $\{1\}$.
    \item Contradictory formulas.
        Now, the set of answers is $\{0\}$.
    \item Satisfiable but not tautological.
        Here, we have both values: $\{0, 1\}$.
\end{itemize}
The last case is the interesting one.
Note the actual return value for this case is $1$,
which corresponds exactly to the maximum of this set.
We may define the computation using exactly this idea.

\begin{definition}
    If every branch of the computation of $M$ on $x$ halts,
    define the value returned by $M$ on $x$
    as being the lexicographically greatest value
    left by $M$ in any of its branches.
\end{definition}

The requirement that every branch halts
guarantees that this yields an acceptable Gödel numbering;
hence, the first requirement was met.

To apply the Blum axioms,
we define the time complexity by being the size of the deepest branch,
if every branch is finite,
and the space complexity as being the largest number of occupied tape cells
in any branch of computation,
if again every branch is finite.
The requirement to the machine to halt
guarantees we can satisfy both axioms.

Although coming from a different route,
Krentel reached a similar definition \cite{Krentel1988}.
He was concerned with optimization problems
and defined $\OptP$ as being the set of all functions
that could be computed in polynomial time
by nondeterministic Turing machines,
according to the definition of this section.
The idea is that these machines optimize the problem they are solving,
by returning the maximum possible value.
(Actually, Krentel included both maximization and minimization problems
in $\OptP$, but the idea was the same.)

\subsection{Valiant's $\#\P$ class}

As observed by Krentel,
the definition of $\OptP$ was achieved by applying
an associative and commutative operator to the set of values
that the nondeterministic machine returns.
Thus,
for every different operator we choose,
we have an alternative definition of nondeterministic computation of functions.
We mention only one such alternative definition,
due to Valiant \cite{Valiant1979}.

\begin{definition}
    If every branch of the computation of $M$ on $x$ halts,
    define the value returned by $M$ on $x$
    as being the number of different accepting branches of computation.
\end{definition}

In the same way that Krentel defined his $\OptP$ class using polynomial bounds,
Valiant's $\#\P$ class is the set of all functions
that can be computed in polynomial time by nondeterministic machines
according to the above definition.

\bibliographystyle{sbc/sbc}
\bibliography{bib/bibliography}

\end{document}
