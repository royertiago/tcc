\documentclass[12pt]{article}
\usepackage{sbc/template}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{example}[definition]{Example}
\newtheorem{proposition}[definition]{Proposition}

\usepackage{complexity}

\sloppy

\title{Blum axioms and nondeterministic computation of functions}

\author{Tiago Royer\inst{1}, Jerusa Marchi\inst{1}}

\address{
    Universidade Federal de Santa Catarina --- Departamento de Informática e Estatística
}

\begin{document}

\maketitle

\begin{abstract}
    In his doctoral thesis,
    Manuel Blum proposed two axioms for complexity measures
    that allows us to talk about complexity in an axiomatic manner.
    His axioms does not even specify the machine model
    --- it just requires it to satisfy some properties.
    Blum axioms, however,
    are defined in the context of function computation.
    This restriction is easy to implement with deterministic machines,
    since there is only one output for a given input,
    but how can a nondeterministic Turing machine compute a function?
    This paper surveys techniques to associate
    nondeterministic machines with functions
    and analyze how they interact with computational complexity.
\end{abstract}

\section{Introduction}

In Theory of Computation,
we usually use languages
to mathematically model problems in the real world.
Decision problems (``yes/no'') are mapped to languages in a very natural way:
just put every ``yes'' instance in the language,
and leave the rest out.
Search problems usually are rewritten as a decision problem,
and then this problem is converted to a language.
For instance,
the task of finding a satisfying assignment for a Boolean formula $\phi$
is reinterpreted to the task of merely deciding whether this assignment exists,
and this task is then converted to a language
--- in this example we have $\SAT$, the Boolean satisfiability problem.
This does the trick when it comes to proving that something is hard;
for instance, if we show that the decision problem is $\NP$-hard or undecidable,
then intuitively the corresponding search problem must be at least as hard.
Therefore,
concepts like ``decidable'', ``$\NP$-complete'', ``polynomial-time decidable''
arise naturally in the context of decision problems.

However, even from the theoretical standpoint,
it is useful to extend these concepts to functions.
For instance,
the concept of polynomial-time computable functions
are central to the definition of Karp reductions.
For single-tape, deterministic Turing machines,
this definition is easy to extend:
A function $f : \{0, 1\}^* \to \{0, 1\}^*$
is said to be \emph{polynomial-time computable}
if there is a Turing machine $M$ and a polynomial $p$ such that,
when given the string $x$ as input,
$M$ halts with $f(x)$ in its tape within $p(|x|)$ steps.

Most extensions to this basic model,
like the use of several tracks, or several tapes, or multidimensional tapes,
can be easily incorporated in the definition of polynomial-time computable.
Except nondeterminism.
We hit a wall right in the start:
how does a nondeterministic machine computes a function in the first place?

This paper presents several attempts to establish
how a nondeterministic Turing machine could compute a function,
and to extend the concept of ``polynomial-time computable'' under each definition.
Section~\ref{sec:quality-standards} sets reasonableness criteria
to both the definition of function computation and complexity of the computation.
Section~\ref{sec:nondeterministic_computation_of_functions}
presents and criticizes the several definitions.

\section{Quality Standards}
\label{sec:quality-standards}

The definition of non-deterministic computation of functions we are trying to make
must encompass both the ``computation'' part
and the ``non-deterministic'' part.

In the context of deciders,
allowing doubly-infinite tapes and multiple tapes,
although simplifies the design and increases the efficiency of the machine,
does not expand the class of languages that can be decided or recognized by the machine.
That is, both models are \emph{computationally equivalent}.
Therefore,
our definition must produce an equivalent model
--- every function that can be computed by deterministic means
must be computable under our new definition and vice-versa.
This is the ``computation'' part.

But nondeterministic deciders,
although computationally equivalent to deterministic ones,
are apparently much faster.
That is, while we have linear-time non-deterministic algorithms for Boolean satisfiability,
the best known deterministic algorithms are still exponential in the worst case.
Nondeterminism seems special in this sense;
although other extensions (multiple tapes and doubly-infinite tapes)
can be simulated under just a polynomial slowdown,
the simulation of nondeterminism seems to require exponential slowdown.%
\footnote{
    Simulating nondeterminism under a polynomial slowdown would show that $\P = \NP$;
    showing that the slowdown must be exponential would show that $\P \neq \NP$.
    Although most researchers expect the later to be the case~\cite[p.~54]{Gasarch2012},
    as Papadimitriou noted~\cite[p.~412]{Papadimitriou1994},
    in the absence of a proof that $\P \neq \NP$
    we should not be too emphatic in stating the simulation \emph{require}
    (as opposed to \emph{seemingly require}) exponential slowdown.
}
Therefore,
our definition must exhibit this apparent exponential speedup
when computing, for instance, the characteristic function of $\SAT$.
This is the ``non-deterministic'' part.

Section~\ref{sec:godel-numberings}
presents a formalization of the ``computation'' part
and section~\ref{sec:blum-axioms}
presents a formalization of the ``non-deterministic'' part.

\subsection{Reasonableness criterion: acceptable Gödel numberings}
\label{sec:godel-numberings}

One of the most important theoretical results concerning Turing machines
is the existence of undecidable problems.
Namely, the \emph{halting problem}
(the task of deciding whether a given Turing machine will halt on a given input)
cannot be solved by Turing machines.
The formalization (and proof) of this fact
requires the definition of some sort of \emph{encoding};
since Turing machines can only reason about strings,
we need somehow to encode Turing machines into strings,
to be able to pose the halting problem as a language question.

Each Turing machine can be associated
to the corresponding partial recursive function it computes.
There are several ways to encode Turing machines as strings,
but what is most important about them is that they allow us
to manipulate these partial recursive functions \emph{indirectly}
--- partial recursive functions are (potentially) infinite objects,
so we cannot write them down on a Turing machine tape,
but we \emph{can} write the encoding of a Turing machine that compute these functions.

Therefore,
these encodings provide a way to associate a string
(which is a finite, manipulable object)
with a partial recursive function
(which is an infinite, mathematical, ``untouchable'' object).
An encoding is an \emph{enumeration} of all partial recursive function.

In a way,
we are going the opposite direction:
instead of associating functions with strings,
we want to associate machines with functions.

One important feature about the standard encodings of deterministic Turing machines
is the Universal Turing Machine Theorem:
the existence of a partial recursive function
$U: \{0, 1\}^* \times \{0, 1\}^* \to \{0, 1\}^*$
% Não sei se $U$ é um bom nome...
such that, if $w$ encodes the machine $M$,
then $U(m, x)$ is the result of running the machine $M$ on $x$.
The machines that compute $U$ are called \emph{universal Turing machines}.

The concept of \emph{acceptable Gödel numbering}
(\cite[p.~41]{Rogers1987},~\cite[p.~324]{Blum1967})
encompasses the existence of universal machines and a little more.
We will use it as our reasonableness criteria to our definitions.%

\begin{definition}
    Let $\mathcal P$ be the set of all partial recursive functions.
    An \emph{acceptable Gödel numbering}
    is a function $\phi : \{0, 1\}^* \to \mathcal P$,
    that associates each string (or program)\footnotemark $w \in \{0, 1\}^*$
    \footnotetext{
        In texts like Rogers'~\cite{Rogers1987},
        the partial recursive functions have the naturals as domain and codomain
        (that is, they are of the form $f: \mathbb N \to \mathbb N$),
        and Gödel numberings associates natural numbers with recursive functions.
        In this paper we will work with binary strings instead of numbers,
        which will simplify the definition of complexity classes
        and allows us to think the string $w$ as a \emph{program} for $\phi_w$
        (see example~\ref{c}).
    }
    to a function $\phi_w \in \mathcal P$,
    that satisfies
    \begin{enumerate}
        \item $\phi$ is surjective;
            that is, every partial recursive function $f \in \mathcal P$
            has a program $w \in \{0, 1\}^*$ such that $\phi_w = f$;
            \label{surjectiveness}
        \item There is a partial recursive function
            $U:\{0, 1\}^* \times \{0, 1\}^* \to \{0, 1\}^*$ such that,
            for every $w$ and $x$,
            $U(w, x)$ is defined if and only if $\phi_w(x)$ is defined,
            and, in this case,
            \begin{equation*}
                U(w, x) = \phi_w(x);
            \end{equation*}
            \label{universal-tm}
        \item There is a total recursive function
            $\sigma:\{0, 1\}^* \times \{0, 1\}^* \to \{0, 1\}^*$ such that,
            for every $y$,
            $\phi_w(x, y)$ is defined if and only if $\phi_{\sigma(w, x)}(y)$ is defined,
            and, in this case,
            \begin{equation*}
                \phi_w(x, y) = \phi_{\sigma(w, x)}(y).
            \end{equation*}
            \label{smn-theorem}
    \end{enumerate}
\end{definition}

This concept captures the intuitive notion of
``well-behaved numbering''.

Condition~\ref{surjectiveness}
guarantees that the image of~$\phi$ is all of~$\mathcal P$,
so that the numbering neither ``forgets'' a partial recursive function
nor generate a function that is not partial recursive.

Condition~\ref{universal-tm} is the universal Turing machine theorem.

Condition~\ref{smn-theorem} is the ``little more'' we mentioned earlier.
It is known as the $S_{mn}$ theorem, or the iteration theorem.
Essentially,
given a partial recursive function of two variables,
we can obtain a partial recursive function of one variable
by fixing the first argument.
The function $\sigma$ provides a systematic way of doing this:
given a description $w$ of a partial recursive function of two variables
and the value $x$ to be fixed as the first variable,
the function returns a machine $\sigma(w, x)$
that computes the same function as $w$ but with the first argument fixed as $x$.

\begin{example}
    Any encoding of deterministic Turing machines as a binary string
    yields an acceptable numbering of the recursive functions.
    That is, fix one of these encodings;
    define $\pi: \{0, 1\}^* \to \mathcal P$ as follows:
    if the string $w$ encodes the Turing machine $M$,
    $\pi_w$ is the partial function computed by $M$.
\end{example}

\begin{example}\label{c}
    Any programming languages can be understood as an acceptable Gödel numbering.
    For example,
    if we restrict a \texttt C program
    to perform input and output only using the standard input and standard output
    (that is, forbid interactions with the user, file reading, GUIs,
    access to system clock, etc.),
    the resulting program will map a binary input to a binary output,
    characterizing a partial recursive function.
    Thus, we can see a \texttt C compiler
    as an implementation of an acceptable Gödel numbering.\footnote{
        Note we are ignoring here issues like compilation and run-time errors.
        These can be dealt with as in the case of Turing machines:
        any invalid program will signify some fixed partial recursive function
        (say, the function that is defined nowhere);
        and any invalid step in computation
        makes the function to be not defined on that input.
    }
\end{example}

\begin{example}
    We can also think of less orthodox numberings.

    As two-stack deterministic pushdown automata are equivalent to Turing machines%
    ~\cite[p.~172]{HopcroftUllman1979},
    any encoding of these kind of automaton yields acceptable Gödel numberings.

    Unrestricted grammars can also simulate Turing machines%
    ~\cite[p.~221]{HopcroftUllman1979};
    so if a grammar $G$ generate pairs $(x, y)$,
    define the corresponding partial recursive function $f$
    by $f(x) = y$ if,
    among all the pairs whose first element is $x$,
    the pair $(x, y)$ is the one with smallest number of productions
    (leave $f$ undefined if there are ties or no pairs with $x$ as first element).
    (Choosing the pair $(x, y)$ with the smaller number of productions
    allows a Turing machine to simulate this function
    by doing a breadth-first search in the grammar,
    guaranteeing the function is partial recursive.)

    And, as an off-line Turing machine
    (a machine with a special read-only tape for its input)
    can simulate any Turing machine without ever writing a $0$ over a~$1$
    \cite[p.~174]{HopcroftUllman1979},
    we can associate an encoding of a off-line Turing machine
    with the function that counts the number of times
    it writes a $0$ over an $1$ before halting
    (the number can be converted to binary and have its most significant digit removed
    to generate all possible binary strings).
    (The machine can choose how many times it will write a $0$ over an $1$,
    thus we can generate any partial recursive function by manipulating this choice.)
\end{example}

\subsection{Efficiency criterion: Blum axioms}
\label{sec:blum-axioms}

The \emph{complexity} of a computation is how much of a resource
that is invested in that computation~\cite[p.~285]{HopcroftUllman1979}.
For each model of computation and each resource under that model,
we can establish a \emph{complexity measure} concerning that resource.
This section is devoted to formalizing this notion.

Note that the complexity measure must be subordinated to the machine model.
For instance,
if we are talking about pushdown automata with two stacks,
we could restrict the machine to operate on one stack each time
(that is, each move must alter at most one stack)
and measure the number of times the automaton switches its ``active'' stack.
This complexity measure makes no sense for Turing machines,
which have no stacks.

Therefore,
we must have an acceptable Gödel numbering $\phi$
to discuss complexity.
We can think that a complexity measure is a way of associating
each program $w$ and each input $x$
with a number $n$,
which is the amount of the measured resource it takes to obtain $\phi_w(x)$
using the program $w$.

As we did with the machine encodings,
we will impose some restrictions on what can be a complexity measure
to be able to manipulate it (at least indirectly).
In our case,
we will use Blum axioms~\cite[p.~324]{Blum1967}.

\begin{definition}
    Given an acceptable Gödel numbering $\phi$,
    a \emph{complexity measure} for $\phi$
    is a function $\Phi:\Sigma^* \times \Sigma^* \to \mathbb N$ of two variables
    that satisfies: \cite[p.~324]{Blum1967}
    \begin{enumerate}
        \item For every $w$ and $x$,
            $\phi_w(x)$ exists if and only if $\Phi(w, x)$ exists.
        \item For every string $w$, $x$ and every natural number $k$,
            the predicate ``$\Phi(w, x) = k$?'' is decidable.
    \end{enumerate}
\end{definition}

$\Phi(w, x)$ is the complexity of computing $\phi_w(x)$
using the program $w$.
The first axiom says that it only makes sense
to talk about the complexity of a computation that ends.
The second axiom gives minimum tools to manipulate $\Phi$ indirectly,
in the same manner we require $\phi$ to be an \emph{acceptable} Gödel numbering.

\begin{example}
    Given the Gödel numbering $\pi$ of the previous chapter,
    the number of steps a Turing machine needs before halting
    is a complexity measure that satisfies Blum axioms.
    The corresponding function $\Phi$ is
    \begin{equation*}
        \Phi(w, x) = \begin{cases}
            k, &\text{if $w$ takes exactly $k$ steps on $x$ before halting} \\
            \text{undefined}, &\text{if $w$ never halts on $x$}
        \end{cases}
    \end{equation*}
    Then, $\Phi(w, x)$ is defined exactly when $\pi_w(x)$ exists
    (that is, when $w$ halts on $x$),
    and we can determine whether $\Phi(w, x) = k$ for a given $k$
    by simulating $w$ on $x$ for exactly $k$ steps.
\end{example}

\begin{example}
    Space complexity requires some care,
    because a machine may never halt even though it remains confined
    in a limited number of cells.
    Thus, we must leave the space complexity of a machine that never halts undefined.
    Formally, define the function $\Phi$ by
    \begin{equation*}
        \Phi(w, x) = \begin{cases}
            k, &\text{if $w$ uses exactly $k$ tape cells on $x$ before halting} \\
            \text{undefined}, &\text{if $w$ never halts on $x$}
        \end{cases}
    \end{equation*}
    This makes $\Phi$ satisfy the first axiom.
    To satisfy the second axiom,
    we must note that,
    if we limit the number of tape cells to $k$,
    there is a finite number of different computation states
    the machine can be.
    Therefore,
    to determine whether $\Phi(w, x) = k$,
    simulate $w$ on $x$ and keep the whole history of computation.
    If, in any point of the simulation,
    the machine $w$ uses more than $k$ tape cells,
    reject --- the answer is ``no''.
    If any two computation states repeat,
    then the machine will loop and never halt
    --- the answer is ``no'' again.
    Otherwise, the machine must halt
    (since there is a finite number of computation states).
    Now, when the machine halts,
    we just need to make sure it actually used exactly $k$ cells in one of its tapes.
\end{example}

\begin{example}
    Choosing $\Phi(w, x) = 0$ for all $w$ and $x$
    creates a function that satisfies the second axiom,
    but not the first.
    Leaving $\Phi(w, x)$ undefined for all $w$ and $x$ such that
    $\pi_w(x)$ does not exists and defining $\Phi(w, x) = 0$ otherwise
    satisfies the first axiom, but not the second.
    This shows the axioms are independent \cite[p.~324]{Blum1967}.
\end{example}

There are other measures that satisfies the Blum axioms
(like, for example,
the number of times a Turing machine changes a symbol in the tape,
the number of times the tape head changes direction,
the number of movements to the left or to the right),
but, before extending these complexity measures to nondeterministic machines,
we must first provide an acceptable Gödel numbering.

\section{Nondeterministic computation of functions}
\label{sec:nondeterministic_computation_of_functions}

This section surveys four approaches
for defining nondeterministic computation of functions.
Sections \ref{sec:godel-numberings} and~\ref{sec:blum-axioms}
can be understood as ``quality requirements''
for the definitions;
that is, the definitions will need to be translatable as
acceptable Gödel numberings,
and the ``natural'' extension of space and time complexity
must satisfy Blum axioms.

\subsection{Hopcroft-Ullman definition}

In their 1979 book,
Hopcroft and Ullman note the need
for defining how a nondeterministic Turing machine can compute a function;
they mention one possible approach \cite[p.~313]{HopcroftUllman1979}:
\begin{quotation}
    We may establish that nondeterministic time and space
    satisfy the axioms if we make an intelligent definition of what it means
    for an NTM to compute a function.
    For example, we might say that $\phi_i(n) = j$
    if and only if there is some sequence of choices by $M_i$ with input $0^n$
    that halts with $0^j$ on the tape,
    and no sequence of choices that leads to halting with some $0^k$, $k \neq j$,
    on the tape.
\end{quotation}
(Hopcroft and Ullman make this definition in the context of integer functions;
in our notation, this means that $\phi_w(x) = y$
if and only if there is some sequence of choices of the machine represented by $w$
when processing the input $x$ that halts with $y$ in the tape,
and no other sequence of choices that leads to halting does so with some $z$,
$z \neq y$, on the tape.)

The problem with their definition is that $\phi_w(x)$ is allowed to be defined,
even if some branch of computation does not halt.
This allows us to solve the complement of the halting problem.

\begin{proposition}
    The function partial $f: \Sigma^* \times \Sigma^* \to \{0, 1\}$ defined by
    \begin{equation*}
        f(w, x) = \begin{cases}
            1, & \text{if the machine $w$ does not halt on $x$.} \\
            \text{undefined}, &\text{if $w$ never halts on $x$.}
        \end{cases}
    \end{equation*}
    is not computable,
    but can be computed by a nondeterministic Turing machine under
    Hopcroft and Ullman's definition.
\end{proposition}

\begin{proof}
    Notice that the domain in which $f$ is defined
    is the complement under $\Sigma^*$ of the halting problem.
    Therefore,
    we can pair a machine that computes $f$
    with a machine that recognizes (but not decides) the halting problem
    to actually decide the halting problem,
    as follows:

    Let $M$ be the machine that computes $f$,
    and $U$ be the universal Turing machine
    (that, on input $(w, x)$,
    either returns $\pi_w(x)$ if it exists
    or loops forever if it doesn't).
    The machine $M'$ that will solve the halting problem
    will simulate $M$ and $U$ simultaneously,
    one move for each machine.
    Since the domains of $M$ and $U$ are complementary,
    for any input $(w, x)$, exactly one of them will halt.
    If is $U$, then we accept because $w$ halts on $x$;
    otherwise, if it is $M$, we reject because $w$ never halts on $x$.
    This solves the halting problem --- a contradiction.
    Hence, no Turing machine can compute $f$.

    But $f$ can be computed under Hopcroft and Ullman's definition as follows:
    on input $(w, x)$,
    create two branches of computation.
    On the first, write $1$ on the tape and halt.
    On the second, simulate the universal Turing machine $U$ in the input,
    and if $U$ halts, write $0$ on the tape and also halt.

    If $w$ halts on $x$,
    there will be two halting branches of computation
    that writes different values on the tape,
    so, by definition, the function is not defined on this input.
    If $w$ never halts,
    then only the first branch will halt
    (and with $1$ written on the tape),
    so the function is defined on this input and its value is $1$.

    Thus, this machine can, under Hopcroft and Ullman's definition,
    compute the noncomputable function $f$.
\end{proof}

Therefore,
using Hopcroft and Ullman's definition,
we could enumerate functions that are not computable;
so, the image of the corresponding ``Gödel numbering''
would include not only computable functions.

A tentative fix to this definition is to force all branches to halt;
but now, as all branches are required to return the same value,
the machine is almost deterministic.
Therefore, if there is a machine $M$ that computes the characteristic function%
\footnote{
    The characteristic function of a set $A \subseteq \Sigma^*$
    is the function $f$ defined by
    \begin{equation*}
        f(x) = \begin{cases}
            1, & \text{if $x \in A$}. \\
            0, & \text{if $x \notin A$}.
        \end{cases}
    \end{equation*}
}
of the satisfiability problem in nondeterministic polynomial time,
we could simulate $M$ on a given input,
choosing (say) always the first option when confronted with nondeterminism.
If this branch of computation returns $1$,
then every branch returns $1$ and the input is satisfiable;
if this branch returns $0$, every branch returns $0$ and the input is unsatisfiable.
We thus could solve $\SAT$ in \emph{deterministic} polynomial time.

Therefore, with this restriction,
we lose the apparent exponential speed up in computation time%
\footnote{
    It is ``apparent'' in the sense that,
    if $\P \neq \NP$,
    we will have this exponential slowdown in some problems
    when moving from nondeterministic to deterministic machines.
}
we have when using nondeterminism.
We thus will analyze the following models
to see whether they also suffer from this problem.

\subsection{Oded Goldreich definition}

\begin{definition}[Goldreich's definition]
    Let $\bot$ be some special symbol not in $\{0, 1\}^*$.
    (This symbol will represents ``don't know'')
    A nondeterministic machine $M$ computes the function $f$ if,
    when processing the input $x$,
    both the following conditions hold \cite[p.~168]{Goldreich2008}:
    \begin{itemize}
        \item Every branch of $M$ halts
            and outputs either $f(x)$ or $\bot$.
        \item At least one branch of $M$ halts with $f(x)$ on the tape.
    \end{itemize}
\end{definition}

The extra symbol $\bot$ sidesteps the possibility of a branch looping forever.
Now,
every branch is required to halt for the value of the function be defined.
Thus,
we can convert a nondeterministic Turing machine to a deterministic machine
that compute the same function,
albeit with an exponential slowdown
--- the deterministic machine just need to simulate all branches until completion,
to actually be sure every branch halts.

This allows us to comply with the requirements to being an acceptable Gödel numbering:
\begin{itemize}
    \item Any deterministic machine can be understood as a nondeterministic machine
        with a single branch,
        so every computable function appears in the corresponding numbering.
        Thus, the numbering is surjective --- it enumerates every computable function.
    \item Any nondeterministic machine can be simulated by some deterministic machine,
        so the enumeration codomain is the set of computable functions.
    \item This conversion can be done mechanically,
        so we can use the same universal machine and $\sigma$ function
        of the standard Gödel numbering $\pi$
        to comply with the universal machine theorem and the $S_{mn}$ theorem.
\end{itemize}

At least partially,
we can compute the characteristic function of the satisfiability problem
in linear time using this model.
The machine $M$ that will do the calculation will guess an assignment
and write $1$ if it is satisfying and write $\bot$ if it isn't.
This computes in linear time the function $f$, defined by
\begin{equation*}
    f(\varphi) = \begin{cases}
        1, & \text{if $\varphi$ is satisfiable.} \\
        \text{undefined}, & \text{if $\varphi$ is unsatisfiable.} \\
    \end{cases}
\end{equation*}
However,
this function falls short of being exactly $\SAT$'s characteristic function:
$f(\varphi)$ ought to be zero for unsatisfiable $\varphi$.
Although we cannot prove a strong assertion as
``if this works then $\P = \NP$'',
we can come close.

\begin{proposition}
    If there is a nondeterministic Turing machine
    that computes in polynomial time, according to Goldreich's definition,
    the characteristic function of the satisfiability problem,
    then $\NP = \coNP$.
\end{proposition}

($\NP = \coNP$ implies that $\NP = \PH$; that is,
the polynomial hierarchy collapses to the first level.)

\begin{proof}
    Suppose $M$ is the machine that computes $\SAT$'s characteristic function,
    under Goldreich definition, in polynomial time.

    To solve $\overline \SAT$,
    the complement of $\SAT$,
    using $\NP$ resources,
    create a nondeterministic machine $M'$ that will simulate $M$ on its input.
    On each branch, if $M$ returned either $\bot$ or $1$, reject;
    if $M$ returns $0$, accept.

    If the current instance is satisfiable,
    all branches will return either $\bot$ or $1$,
    so we are right in rejecting it;
    otherwise, if the current instance is unsatisfiable,
    at least some branch will return $0$,
    so we will correctly reject the input.

    Since the complement of $\SAT$ is $\coNP$-complete,
    any language in $\coNP$ can thus be solved with a nondeterministic machine;
    hence, $\coNP \subseteq \NP$.

    Similarly,
    every language $L$ of $\NP$ has a many-one reduction to $\SAT$;
    thus, the complement $\overline L$ has a many-one reduction
    to $\overline \SAT$.
    Hence, composing the reduction with the above algorithm
    that solves $\overline \SAT$ using a nondeterministic machine,
    we conclude that $\overline L \in \NP$.
    Thus, by definition, $L \in \coNP$.
    So, $\NP \subseteq \coNP$.

    This shows $\NP = \coNP$.
\end{proof}

Therefore, even though Goldreich's definition
yields an acceptable Gödel numbering,
it also have trouble in transposing the exponential speedup
we have using nondeterminism.

\subsection{Krentel's $\OptP$ class}

From the last two definitions,
we know we must somehow allow the machine to return several values
and pick only one to be the return value.

We can arrive at the definition proposed by Krentel
analyzing the behavior of a nondeterministic machine to solve the satisfiability problem
that has undergone the process applied to deterministic machines
to transform a decider in a computer for the characteristic function.
More precisely,
pick $M$ a nondeterministic decider for $\SAT$,
and make $M$ write $1$ in the tape if it found a satisfying assignment
and $0$ if it didn't.
The propositional formulas will fall in three categories.
\begin{itemize}
    \item Tautological formulas.
        The set of possible answers for these formulas is only $\{1\}$.
    \item Contradictory formulas.
        Now, the set of answers is $\{0\}$.
    \item Satisfiable but not tautological.
        Here, we have both values: $\{0, 1\}$.
\end{itemize}
The last case is the interesting one.
Note the actual return value for this case is $1$,
which corresponds exactly to the maximum of this set.
We may define the computation using exactly this idea.

\begin{definition}
    If every branch of the computation of $M$ on $x$ halts,
    define the value returned by $M$ on $x$
    as being the lexicographically greatest value
    left by $M$ in any of its branches.
\end{definition}

The requirement that every branch halts
guarantees that this yields an acceptable Gödel numbering;
hence, the first requirement was met.

To apply the Blum axioms,
we define the time complexity by being the size of the deepest branch,
if every branch is finite,
and the space complexity as being the largest number of occupied tape cells
in any branch of computation,
if again every branch is finite.
The requirement to the machine to halt
guarantees we can satisfy both axioms.

Although coming from a different route,
Krentel reached a similar definition \cite{Krentel1988}.
He was concerned with optimization problems
and defined $\OptP$ as being the set of all functions
that could be computed in polynomial time
by nondeterministic Turing machines,
according to the definition of this section.
The idea is that these machines optimize the problem they are solving,
by returning the maximum possible value.
(Actually, Krentel included both maximization and minimization problems
in $\OptP$, but the idea was the same.)

\subsection{Valiant's $\#\P$ class}

As observed by Krentel,
the definition of $\OptP$ was achieved by applying
an associative and commutative operator to the set of values
that the nondeterministic machine returns.
Thus,
for every different operator we choose,
we have an alternative definition of nondeterministic computation of functions.
We mention only one such alternative definition,
due to Valiant \cite{Valiant1979}.

\begin{definition}
    If every branch of the computation of $M$ on $x$ halts,
    define the value returned by $M$ on $x$
    as being the number of different accepting branches of computation.
\end{definition}

In the same way that Krentel defined his $\OptP$ class using polynomial bounds,
Valiant's $\#\P$ class is the set of all functions
that can be computed in polynomial time by nondeterministic machines
according to the above definition.

\bibliographystyle{sbc/sbc}
\bibliography{bib/bibliography}

\end{document}
