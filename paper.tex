\documentclass[12pt]{article}
\usepackage{sbc/template}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{example}[definition]{Example}
\newtheorem{proposition}[definition]{Proposition}

\usepackage{complexity}

\sloppy

\title{Blum axioms and nondeterministic computation of functions}

\author{Tiago Royer\inst{1}}

\address{
    Departamento de Informática e Estatística
    --- Universidade Federal de Santa Catarina
    \email{royertiago@gmail.com}
}

\begin{document}

\maketitle

\begin{abstract}
    In his doctoral thesis,
    Manuel Blum proposed two axioms for complexity measures
    that allows us to talk about complexity in an axiomatic manner.
    His axioms does not even specify the machine model
    --- it just requires it to satisfy some properties.
    Blum axioms, however,
    are defined in the context of function computation.
    This restriction is easy to implement with deterministic machines,
    since there is only one output for a given input,
    but how can a nondeterministic Turing machine compute a function?
    This paper surveys techniques to associate
    nondeterministic machines with functions
    and analyze how they interact with computational complexity.
\end{abstract}

\section{Introduction}

Theory of Computation is mostly concerned about models of computation.
In general, for each model of computation,
there is some standard mathematical ``procedure''
for finding the language associated with a device
(one instance of the model).
This fixation with languages has many nice features;
for example,
we have the duality between recognizers and generators.
We may even go further and identify the concept of ``model of computation''
with the task of representing an infinite language
with some finite amount of information.
This provides a simple way of comparing the relative power of two models of computation:
just see ``how many languages'' each model can represent
--- the one with ``more'' languages ``win''\footnote{
    That is,
    if every language that can be represented with a given model of computation $A$
    can also be represented with a given model $B$,
    but there are languages representable in $B$ that are not representable in $A$,
    we say that $B$ is more \emph{powerful} or \emph{expressive} than $A$.
    $A$ and $B$ are said to be \emph{equivalent}
    if every language representable in $A$ is representable in $B$ and vice versa.
}.

Most problems need to be adapted to languages
in order to discuss its representability.

\section{Gödel numberings}

% TODO: Note that this is a simplification

Gödel's famous Incompleteness Theorem says that
any correct and consistent formal system that includes the Peano arithmetic
will have statements that are true under that system,
but \emph{cannot be proven} under that system.
In essence,
in the proof of this theorem,
Gödel created self-referential proposition $\varphi$
that essentially says ``$\varphi$ is not provable''.
Then, if $\varphi$ is false,
by it's own assertion, it must be provable;
but, as the system is consistent,
this would mean that $\varphi$ is true
--- a contradiction.
Hence, $\varphi$ must be true.
But, as it is true,
there cannot be a proof under the current formal system to it
--- that is exactly what $\varphi$ asserts.
So,
we get a proposition we know it is true,
but we cannot prove it using only tools of that system.

We can have a glimpse at how Gödel managed to construct a formula like $\varphi$
by analyzing how Turing constructed a language
that cannot be decided by Turing machines.

The language built by Turing is known today as the halting problem.
In essence,
you are given a Turing machine $M$ and an input $w$
and must decide whether $M$ eventually halts when processing $w$.
To prove that this problem is undecidable,
Turing had first to somehow encode this problem as a language
(because all a Turing machine can understand are sentences of a language);
the key point is that the Turing machine formalism
had to be encoded into words that could be fed to Turing machines.
Thus we could pick any machine and feed its own description as an input;
this form of self-reference is analogous
to Gödel's unprovable but true sentence.

In our context,
a \emph{Gödel numbering} will simply be a means
of associating every word $w$ of $\{0, 1\}^*$
with a computable function.
Section~\ref{sec:acceptable-godel-numberings} shows a refinement of this notion,
and section~\ref{sec:blum-axioms}
defines the Blum axioms over the refined definition.

\subsection{Acceptable Gödel numberings}
\label{sec:acceptable-godel-numberings}

\begin{definition}
    Let $\mathcal P$ be the the set of partial computable functions.
    A \emph{Gödel numbering}
    is a function $\phi: \{0, 1\}^* \to \mathcal P$
    that is surjective.
\end{definition}

A Gödel numbering formalizes the concept of associating a word $w$ of $\{0, 1\}^*$
with a partial recursive function $f$ of $\mathcal P$.
We can think of $w$ as being the ``source code'' for the ``program'' $f$;
we denote $f = \phi(w)$ by $\phi_w$.

Because Gödel numberings are infinite mathematical objects,
Turing machines cannot manipulate them directly.
We thus need some technique to manipulate the numbering indirectly.

Call $\pi$ the standard Gödel numbering
that corresponds to the standard representation of Turing machines;
that is, if $w$ is the encoding of a Turing machine $M$,
then $\pi_w$ is the partial function computed by $M$.
We can manipulate $\pi$ indirectly, for instance,
by means of a universal Turing machine $U$.
Given a program $w$ and an input $x$,
if $\pi_w(x)$ exists,
then the output of the machine $U$ when its input is the pair $(w, x)$
is exactly $\pi_w(x)$.
Therefore,
even tough we did not directly manipulate the numbering $\pi$
or calculate $\pi_w$,
we did manage to indirectly compute the value of $\pi_w(x)$.
This is the \emph{universal machine theorem}.

We can also manipulate the source code directly.
Suppose $w$ represents a Turing machine that computes a function of two variables $f$.
Given two inputs $x$ and $y$, we can compute $f(x, y) = \pi_w(x, y)$
using the universal Turing machine.
If we are given a single input $x$ and leave the second variable free,
we have a function $g$ of one variable, such that
\begin{equation*}
    g(y) = f(x, y).
\end{equation*}
That is, we fixed the first input to be $x$.

This function $g$ is computable;
in fact, we can obtain a source code $w'$ for $g$ from $w$
--- just modify the machine represented by $w$
so that, on input $y$,
it writes $x$ on the tape and runs the original algorithm.%
\footnote{
    Notice we are not manipulating the machine directly,
    only its representation as a string of bits.
}
This kind of modification can be done for any source code $w$
and any input $x$;
there is a computable function $\sigma$ of two variables
that is defined for every $w$ and $x$ such that,
for every $y$,
$\pi_w(x, y)$ is defined if and only if $\pi_{\sigma(w, x)}(y)$ is defined,
and, in this case,
\begin{equation*}
    \pi_w(x, y) = \pi_{\sigma(w, x)}(y).
\end{equation*}
This is the \emph{$S_{mn}$ theorem}.%
\footnote{
    The ``full version'' of this theorem asserts that,
    for any $m$ and $n$,
    there is a computable function $\sigma$ that,
    given a program $x$ for a function of $m + n$ variables
    and $n$ chosen values $y_1, \dots, y_m$,
    \begin{equation*}
        \pi_{\sigma(x, y_1, \dots, y_m)}(z_1, \dots, z_n) =
            \pi_x(y_1, \dots, y_m, z_1, \dots, z_n);
    \end{equation*}
    hence its name \cite[p.~23]{Rogers1987}.
}

These two theorems are all that Blum requires from a Gödel numbering
to define his axiomatic notion of complexity.
We have a special name (due to Rogers) for such numbering.

\begin{definition}
    An \emph{acceptable Gödel numbering}
    is a Gödel numbering $\phi$
    that satisfies both the universal machine theorem
    and the $S_{mn}$ theorem \cite[p.~41]{Rogers1987}.
    That is, there are computable functions $f$ and $\sigma$
    that satisfies
    \begin{itemize}
        \item For every $w$ and $x$,
            $f(w, x)$ is defined if and only if $\phi_w(x)$ is defined,
            and, in this case,
            \begin{equation*}
                f(w, x) = \phi_w(x);
            \end{equation*}
        \item $\sigma$ is defined for every $w$ and $x$,
            and, for every $y$,
            $\phi_w(x, y)$ is defined if and only if $\phi_{\sigma(w, x)}(y)$ is defined,
            and, in this case,
            \begin{equation*}
                \phi_w(x, y) = \phi_{\sigma(w, x)}(y).
            \end{equation*}
    \end{itemize}
\end{definition}

\section{Blum axioms}
\label{sec:blum-axioms}

With the mathematical notion of an acceptable Gödel numbering,
we can now define the Blum axioms for complexity measures.

\begin{definition}
    Given an acceptable Gödel numbering $\phi$,
    a \emph{complexity measure} for $\phi$
    is a function $\Phi:\Sigma^* \times \Sigma^* \to \mathbb N$ of two variables
    that satisfies: \cite[p.~324]{Blum1967}
    \begin{enumerate}
        \item For every $w$ and $x$,
            $\phi_w(x)$ exists if and only if $\Phi(w, x)$ exists.
        \item For every string $w$, $x$ and every natural number $k$,
            the predicate ``$\Phi(w, x) = k$?'' is decidable.
    \end{enumerate}
\end{definition}

$\Phi(w, x)$ is the complexity of computing $\phi_w(x)$
using the program $w$.
The first axiom says that it only makes sense
to talk about the complexity of a computation that ends.
The second axiom gives minimum tools to manipulate $\Phi$ indirectly,
in the same manner we require $\phi$ to be an \emph{acceptable} Gödel numbering.

\begin{example}
    Given the Gödel numbering $\pi$ of the previous chapter,
    the number of steps a Turing machine needs before halting
    is a complexity measure that satisfies Blum axioms.
    The corresponding function $\Phi$ is
    \begin{equation*}
        \Phi(w, x) = \begin{cases}
            k, &\text{if $w$ takes exactly $k$ steps on $x$ before halting} \\
            \text{undefined}, &\text{if $w$ never halts on $x$}
        \end{cases}
    \end{equation*}
    Then, $\Phi(w, x)$ is defined exactly when $\pi_w(x)$ exists
    (that is, when $w$ halts on $x$),
    and we can determine whether $\Phi(w, x) = k$ for a given $k$
    by simulating $w$ on $x$ for exactly $k$ steps.
\end{example}

\begin{example}
    Space complexity requires some care,
    because a machine may never halt even though it remains confined
    in a limited number of cells.
    Thus, we must leave the space complexity of a machine that never halts undefined.
    Formally, define the function $\Phi$ by
    \begin{equation*}
        \Phi(w, x) = \begin{cases}
            k, &\text{if $w$ uses exactly $k$ tape cells on $x$ before halting} \\
            \text{undefined}, &\text{if $w$ never halts on $x$}
        \end{cases}
    \end{equation*}
    This makes $\Phi$ satisfy the first axiom.
    To satisfy the second axiom,
    we must note that,
    if we limit the number of tape cells to $k$,
    there is a finite number of different computation states
    the machine can be.
    Therefore,
    to determine whether $\Phi(w, x) = k$,
    simulate $w$ on $x$ and keep the whole history of computation.
    If, in any point of the simulation,
    the machine $w$ uses more than $k$ tape cells,
    reject --- the answer is ``no''.
    If any two computation states repeat,
    then the machine will loop and never halt
    --- the answer is ``no'' again.
    Otherwise, the machine must halt
    (since there is a finite number of computation states).
    Now, when the machine halts,
    we just need to make sure it actually used exactly $k$ cells in one of its tapes.
\end{example}

\begin{example}
    Choosing $\Phi(w, x) = 0$ for all $w$ and $x$
    creates a function that satisfies the second axiom,
    but not the first.
    Leaving $\Phi(w, x)$ undefined for all $w$ and $x$ such that
    $\pi_w(x)$ does not exists and defining $\Phi(w, x) = 0$ otherwise
    satisfies the first axiom, but not the second.
    This shows the axioms are independent \cite[p.~324]{Blum1967}.
\end{example}

There are other measures that satisfies the Blum axioms
(like, for example,
the number of times a Turing machine changes a symbol in the tape,
the number of times the tape head changes direction,
the number of movements to the left or to the right),
but, before extending these complexity measures to nondeterministic machines,
we must first provide an acceptable Gödel numbering.

\section{Nondeterministic computation of functions}

This section surveys four approaches
for defining nondeterministic computation of functions.
Sections \ref{sec:acceptable-godel-numberings} and~\ref{sec:blum-axioms}
can be understood as ``quality requirements''
for the definitions;
that is, the definitions will need to be translatable as
acceptable Gödel numberings,
and the ``natural'' extension of space and time complexity
must satisfy Blum axioms.

\subsection{Hopcroft-Ullman definition}

In their 1979 book,
Hopcroft and Ullman note the need
for defining how a nondeterministic Turing machine can compute a function;
they mention one possible approach \cite[p.~313]{HopcroftUllman1979}:
\begin{quotation}
    We may establish that nondeterministic time and space
    satisfy the axioms if we make an intelligent definition of what it means
    for an NTM to compute a function.
    For example, we might say that $\phi_i(n) = j$
    if and only if there is some sequence of choices by $M_i$ with input $0^n$
    that halts with $0^j$ on the tape,
    and no sequence of choices that leads to halting with some $0^k$, $k \neq j$,
    on the tape.
\end{quotation}
(Hopcroft and Ullman make this definition in the context of integer functions;
in our notation, this means that $\phi_w(x) = y$
if and only if there is some sequence of choices of the machine represented by $w$
when processing the input $x$ that halts with $y$ in the tape,
and no other sequence of choices that leads to halting does so with some $z$,
$z \neq y$, on the tape.)

The problem with their definition is that $\phi_w(x)$ is allowed to be defined,
even if some branch of computation does not halt.
This allows us to solve the complement of the halting problem.

\begin{proposition}
    The function partial $f: \Sigma^* \times \Sigma^* \to \{0, 1\}$ defined by
    \begin{equation*}
        f(w, x) = \begin{cases}
            1, & \text{if the machine $w$ does not halt on $x$.} \\
            \text{undefined}, &\text{if $w$ never halts on $x$.}
        \end{cases}
    \end{equation*}
    is not computable,
    but can be computed by a nondeterministic Turing machine under
    Hopcroft and Ullman's definition.
\end{proposition}

\begin{proof}
    Notice that the domain in which $f$ is defined
    is the complement under $\Sigma^*$ of the halting problem.
    Therefore,
    we can pair a machine that computes $f$
    with a machine that recognizes (but not decides) the halting problem
    to actually decide the halting problem,
    as follows:

    Let $M$ be the machine that computes $f$,
    and $U$ be the universal Turing machine
    (that, on input $(w, x)$,
    either returns $\pi_w(x)$ if it exists
    or loops forever if it doesn't).
    The machine $M'$ that will solve the halting problem
    will simulate $M$ and $U$ simultaneously,
    one move for each machine.
    Since the domains of $M$ and $U$ are complementary,
    for any input $(w, x)$, exactly one of them will halt.
    If is $U$, then we accept because $w$ halts on $x$;
    otherwise, if it is $M$, we reject because $w$ never halts on $x$.
    This solves the halting problem --- a contradiction.
    Hence, no Turing machine can compute $f$.

    But $f$ can be computed under Hopcroft and Ullman's definition as follows:
    on input $(w, x)$,
    create two branches of computation.
    On the first, write $1$ on the tape and halt.
    On the second, simulate the universal Turing machine $U$ in the input,
    and if $U$ halts, write $0$ on the tape and also halt.

    If $w$ halts on $x$,
    there will be two halting branches of computation
    that writes different values on the tape,
    so, by definition, the function is not defined on this input.
    If $w$ never halts,
    then only the first branch will halt
    (and with $1$ written on the tape),
    so the function is defined on this input and its value is $1$.

    Thus, this machine can, under Hopcroft and Ullman's definition,
    compute the noncomputable function $f$.
\end{proof}

Therefore,
using Hopcroft and Ullman's definition,
we could enumerate functions that are not computable;
so, the image of the corresponding ``Gödel numbering''
would include not only computable functions.

A tentative fix to this definition is to force all branches to halt;
but now, as all branches are required to return the same value,
the machine is almost deterministic.
Therefore, if there is a machine $M$ that computes the characteristic function%
\footnote{
    The characteristic function of a set $A \subseteq \Sigma^*$
    is the function $f$ defined by
    \begin{equation*}
        f(x) = \begin{cases}
            1, & \text{if $x \in A$}. \\
            0, & \text{if $x \notin A$}.
        \end{cases}
    \end{equation*}
}
of the satisfiability problem in nondeterministic polynomial time,
we could simulate $M$ on a given input,
choosing (say) always the first option when confronted with nondeterminism.
If this branch of computation returns $1$,
then every branch returns $1$ and the input is satisfiable;
if this branch returns $0$, every branch returns $0$ and the input is unsatisfiable.
We thus could solve $\SAT$ in \emph{deterministic} polynomial time.

Therefore, with this restriction,
we lose the apparent exponential speed up in computation time%
\footnote{
    It is ``apparent'' in the sense that,
    if $\P \neq \NP$,
    we will have this exponential slowdown in some problems
    when moving from nondeterministic to deterministic machines.
}
we have when using nondeterminism.
We thus will analyze the following models
to see whether they also suffer from this problem.

\subsection{Oded Goldreich definition}

\begin{definition}[Goldreich's definition]
    Let $\bot$ be some special symbol not in $\{0, 1\}^*$.
    (This symbol will represents ``don't know'')
    A nondeterministic machine $M$ computes the function $f$ if,
    when processing the input $x$,
    both the following conditions hold \cite[p.~168]{Goldreich2008}:
    \begin{itemize}
        \item Every branch of $M$ halts
            and outputs either $f(x)$ or $\bot$.
        \item At least one branch of $M$ halts with $f(x)$ on the tape.
    \end{itemize}
\end{definition}

The extra symbol $\bot$ sidesteps the possibility of a branch looping forever.
Now,
every branch is required to halt for the value of the function be defined.
Thus,
we can convert a nondeterministic Turing machine to a deterministic machine
that compute the same function,
albeit with an exponential slowdown
--- the deterministic machine just need to simulate all branches until completion,
to actually be sure every branch halts.

This allows us to comply with the requirements to being an acceptable Gödel numbering:
\begin{itemize}
    \item Any deterministic machine can be understood as a nondeterministic machine
        with a single branch,
        so every computable function appears in the corresponding numbering.
        Thus, the numbering is surjective --- it enumerates every computable function.
    \item Any nondeterministic machine can be simulated by some deterministic machine,
        so the enumeration codomain is the set of computable functions.
    \item This conversion can be done mechanically,
        so we can use the same universal machine and $\sigma$ function
        of the standard Gödel numbering $\pi$
        to comply with the universal machine theorem and the $S_{mn}$ theorem.
\end{itemize}

At least partially,
we can compute the characteristic function of the satisfiability problem
in linear time using this model.
The machine $M$ that will do the calculation will guess an assignment
and write $1$ if it is satisfying and write $\bot$ if it isn't.
This computes in linear time the function $f$, defined by
\begin{equation*}
    f(\varphi) = \begin{cases}
        1, & \text{if $\varphi$ is satisfiable.} \\
        \text{undefined}, & \text{if $\varphi$ is unsatisfiable.} \\
    \end{cases}
\end{equation*}
However,
this function falls short of being exactly $\SAT$'s characteristic function:
$f(\varphi)$ ought to be zero for unsatisfiable $\varphi$.
Although we cannot prove a strong assertion as
``if this works then $\P = \NP$'',
we can come close.

\begin{proposition}
    If there is a nondeterministic Turing machine
    that computes in polynomial time, according to Goldreich's definition,
    the characteristic function of the satisfiability problem,
    then $\NP = \coNP$.
\end{proposition}

($\NP = \coNP$ implies that $\NP = \PH$; that is,
the polynomial hierarchy collapses to the first level.)

\begin{proof}
    Suppose $M$ is the machine that computes $\SAT$'s characteristic function,
    under Goldreich definition, in polynomial time.

    To solve $\overline \SAT$,
    the complement of $\SAT$,
    using $\NP$ resources,
    create a nondeterministic machine $M'$ that will simulate $M$ on its input.
    On each branch, if $M$ returned either $\bot$ or $1$, reject;
    if $M$ returns $0$, accept.

    If the current instance is satisfiable,
    all branches will return either $\bot$ or $1$,
    so we are right in rejecting it;
    otherwise, if the current instance is unsatisfiable,
    at least some branch will return $0$,
    so we will correctly reject the input.

    Since the complement of $\SAT$ is $\coNP$-complete,
    any language in $\coNP$ can thus be solved with a nondeterministic machine;
    hence, $\coNP \subseteq \NP$.

    Similarly,
    every language $L$ of $\NP$ has a many-one reduction to $\SAT$;
    thus, the complement $\overline L$ has a many-one reduction
    to $\overline \SAT$.
    Hence, composing the reduction with the above algorithm
    that solves $\overline \SAT$ using a nondeterministic machine,
    we conclude that $\overline L \in \NP$.
    Thus, by definition, $L \in \coNP$.
    So, $\NP \subseteq \coNP$.

    This shows $\NP = \coNP$.
\end{proof}

Therefore, even though Goldreich's definition
yields an acceptable Gödel numbering,
it also have trouble in transposing the exponential speedup
we have using nondeterminism.

\subsection{Krentel's $\OptP$ class}

From the last two definitions,
we know we must somehow allow the machine to return several values
and pick only one to be the return value.

We can arrive at the definition proposed by Krentel
analyzing the behavior of a nondeterministic machine to solve the satisfiability problem
that has undergone the process applied to deterministic machines
to transform a decider in a computer for the characteristic function.
More precisely,
pick $M$ a nondeterministic decider for $\SAT$,
and make $M$ write $1$ in the tape if it found a satisfying assignment
and $0$ if it didn't.
The propositional formulas will fall in three categories.
\begin{itemize}
    \item Tautological formulas.
        The set of possible answers for these formulas is only $\{1\}$.
    \item Contradictory formulas.
        Now, the set of answers is $\{0\}$.
    \item Satisfiable but not tautological.
        Here, we have both values: $\{0, 1\}$.
\end{itemize}
The last case is the interesting one.
Note the actual return value for this case is $1$,
which corresponds exactly to the maximum of this set.
We may define the computation using exactly this idea.

\begin{definition}
    If every branch of the computation of $M$ on $x$ halts,
    define the value returned by $M$ on $x$
    as being the lexicographically greatest value
    left by $M$ in any of its branches.
\end{definition}

The requirement that every branch halts
guarantees that this yields an acceptable Gödel numbering;
hence, the first requirement was met.

To apply the Blum axioms,
we define the time complexity by being the size of the deepest branch,
if every branch is finite,
and the space complexity as being the largest number of occupied tape cells
in any branch of computation,
if again every branch is finite.
The requirement to the machine to halt
guarantees we can satisfy both axioms.

Although coming from a different route,
Krentel reached a similar definition \cite{Krentel1988}.
He was concerned with optimization problems
and defined $\OptP$ as being the set of all functions
that could be computed in polynomial time
by nondeterministic Turing machines,
according to the definition of this section.
The idea is that these machines optimize the problem they are solving,
by returning the maximum possible value.
(Actually, Krentel included both maximization and minimization problems
in $\OptP$, but the idea was the same.)

\subsection{Valiant's $\#\P$ class}

As observed by Krentel,
the definition of $\OptP$ was achieved by applying
an associative and commutative operator to the set of values
that the nondeterministic machine returns.
Thus,
for every different operator we choose,
we have an alternative definition of nondeterministic computation of functions.
We mention only one such alternative definition,
due to Valiant \cite{Valiant1979}.

\begin{definition}
    If every branch of the computation of $M$ on $x$ halts,
    define the value returned by $M$ on $x$
    as being the number of different accepting branches of computation.
\end{definition}

In the same way that Krentel defined his $\OptP$ class using polynomial bounds,
Valiant's $\#\P$ class is the set of all functions
that can be computed in polynomial time by nondeterministic machines
according to the above definition.

\bibliographystyle{sbc/sbc}
\bibliography{bib/bibliography}

\end{document}
